{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5cdbcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The pyinstrument extension is already loaded. To reload it, use:\n",
      "  %reload_ext pyinstrument\n"
     ]
    }
   ],
   "source": [
    "# auto-load when code changes outside\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext pyinstrument\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "12fa6a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx as onnx\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "\n",
    "from src.baseline.vocabulary import Vocabulary\n",
    "from src.utils import print_time, list_of_tensors_to_numpy_arr, plot_image, plot_im\n",
    "from src.accuracy import Accuracy\n",
    "from src.baseline.coa_model import get_new_model,load_model, train_validate_test_split, init_testing_model, test_model, test_rand_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "25fd47a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0\n",
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf67d490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a13d222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "82cc65cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "\n",
    "embed_size=300\n",
    "vocab_size = 36\n",
    "attention_dim=256\n",
    "encoder_dim=2048\n",
    "decoder_dim=512\n",
    "learning_rate = 3e-4\n",
    "drop_prob=0.3\n",
    "ignored_idx = 0\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "hyper_params = {'embed_size': embed_size,\n",
    "                'attention_dim': attention_dim,\n",
    "                'encoder_dim': encoder_dim,\n",
    "                'decoder_dim': decoder_dim,\n",
    "                'vocab_size': vocab_size\n",
    "              }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b80e8",
   "metadata": {},
   "source": [
    "# Test the loaded model on synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c61fc8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 30 test images\n"
     ]
    }
   ],
   "source": [
    "# data_location = '/home/space/datasets/COA/generated-data-api'\n",
    "# data_location =  '/home/space/datasets/COA/generated-data-api-small'\n",
    "# data_location =  '/home/space/datasets/COA/generated-data-api-large'\n",
    "\n",
    "data_location =  '../baseline-gen-data/small'\n",
    "root_folder_images = data_location + '/images'\n",
    "\n",
    "test_caption_file = data_location + '/test_captions_psumsq.txt'\n",
    "df = pd.read_csv(test_caption_file)\n",
    "\n",
    "print(\"There are {} test images\".format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6db3dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/baseline/attention_model_03.14.2022-22:14:21.pth'\n",
    "\n",
    "model, optimizer, loss,criterion = load_model(model_path, \n",
    "                                    hyper_params, \n",
    "                                    learning_rate,\n",
    "                                    drop_prob, \n",
    "                                    ignored_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53074260",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1\n",
    "!export CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5cc0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 5\n",
    "NUM_WORKER = 2 #### this needs multi-core\n",
    "freq_threshold = 5\n",
    "batch_size = 256\n",
    "\n",
    "# 30 minutes to create those, as it's baseline, i ran it several times and it's the same\n",
    "vocab = Vocabulary(freq_threshold)\n",
    "vocab.stoi = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'lion': 4, 'rampant': 5, 'passt': 6, 'guard': 7, 'head': 8, 'lions': 9, 'cross': 10, 'moline': 11, 'patonce': 12, 'eagle': 13, 'doubleheaded': 14, 'eagles': 15, 'a': 16, 'b': 17, 'o': 18, 's': 19, 'g': 20, 'e': 21, 'v': 22, '1': 23, '2': 24, '3': 25, '4': 26, '5': 27, '6': 28, '7': 29, '8': 30, '9': 31, '10': 32, '11': 33, 'border': 34, '&': 35}\n",
    "vocab.itos = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>', 4: 'lion', 5: 'rampant', 6: 'passt', 7: 'guard', 8: 'head', 9: 'lions', 10: 'cross', 11: 'moline', 12: 'patonce', 13: 'eagle', 14: 'doubleheaded', 15: 'eagles', 16: 'a', 17: 'b', 18: 'o', 19: 's', 20: 'g', 21: 'e', 22: 'v', 23: '1', 24: '2', 25: '3', 26: '4', 27: '5', 28: '6', 29: '7', 30: '8', 31: '9', 32: '10', 33: '11', 34: 'border', 35: '&'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04960f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "torch.Size([1, 3, 500, 500])\n",
      "mean, std: tensor(0.9773) tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "test_loader, test_dataset = init_testing_model(test_caption_file, \n",
    "                                               root_folder_images, \n",
    "                                               NUM_WORKER,\n",
    "                                               vocab,\n",
    "                                               batch_size, \n",
    "                                               device, \n",
    "                                               pin_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57536b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "No shield color found in this label: \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\"\n",
      "Test Acuuracy (in progress): 0.000000\n",
      "\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "Test Loss (final): nan\n",
      "\n",
      "Test Accuracy (Overall): 0.0%\n"
     ]
    }
   ],
   "source": [
    "test_losses, accuracy_test_list, acc_test_score, test_loss = test_model(model, \n",
    "                                                                        criterion,\n",
    "                                                                        test_loader, \n",
    "                                                                        test_dataset, \n",
    "                                                                        vocab_size, \n",
    "                                                                        device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1927f99b",
   "metadata": {},
   "source": [
    "## Visualizing the attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebe98616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "test_rand_image(model,test_dataset,test_loader,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa0f7a1",
   "metadata": {},
   "source": [
    "# Test the loaded model on real data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "afdf3b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 269 test images\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>psum</th>\n",
       "      <th>psum_sq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1739_A G cross patonce.jpg</td>\n",
       "      <td>A G cross patonce</td>\n",
       "      <td>724933.00000</td>\n",
       "      <td>557413.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22117_O B cross patriarchal.jpg</td>\n",
       "      <td>O B cross patriarchal</td>\n",
       "      <td>696633.87500</td>\n",
       "      <td>521719.93750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2870_O S lion rampant.jpg</td>\n",
       "      <td>O S lion rampant</td>\n",
       "      <td>370219.71875</td>\n",
       "      <td>231043.09375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6870_S O eagle.jpg</td>\n",
       "      <td>S O eagle</td>\n",
       "      <td>840800.62500</td>\n",
       "      <td>661782.93750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18746_S A eagle.jpg</td>\n",
       "      <td>S A eagle</td>\n",
       "      <td>880971.43750</td>\n",
       "      <td>601956.43750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>398_A S lion rampant.jpg</td>\n",
       "      <td>A S lion rampant</td>\n",
       "      <td>673480.62500</td>\n",
       "      <td>517651.34375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>249_O G 2 lions passt.jpg</td>\n",
       "      <td>O G 2 lions passt</td>\n",
       "      <td>871046.06250</td>\n",
       "      <td>677358.06250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>4459_B O eagle.jpg</td>\n",
       "      <td>B O eagle</td>\n",
       "      <td>621500.62500</td>\n",
       "      <td>425808.43750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>5302_O B cross moline.jpg</td>\n",
       "      <td>O B cross moline</td>\n",
       "      <td>736149.62500</td>\n",
       "      <td>530970.68750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>7881_G O 2 lions passt guard.jpg</td>\n",
       "      <td>G O 2 lions passt guard</td>\n",
       "      <td>689131.37500</td>\n",
       "      <td>483920.34375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>269 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                image                  caption          psum  \\\n",
       "0          1739_A G cross patonce.jpg        A G cross patonce  724933.00000   \n",
       "1     22117_O B cross patriarchal.jpg    O B cross patriarchal  696633.87500   \n",
       "2           2870_O S lion rampant.jpg         O S lion rampant  370219.71875   \n",
       "3                  6870_S O eagle.jpg                S O eagle  840800.62500   \n",
       "4                 18746_S A eagle.jpg                S A eagle  880971.43750   \n",
       "..                                ...                      ...           ...   \n",
       "264          398_A S lion rampant.jpg         A S lion rampant  673480.62500   \n",
       "265         249_O G 2 lions passt.jpg        O G 2 lions passt  871046.06250   \n",
       "266                4459_B O eagle.jpg                B O eagle  621500.62500   \n",
       "267         5302_O B cross moline.jpg         O B cross moline  736149.62500   \n",
       "268  7881_G O 2 lions passt guard.jpg  G O 2 lions passt guard  689131.37500   \n",
       "\n",
       "          psum_sq  \n",
       "0    557413.50000  \n",
       "1    521719.93750  \n",
       "2    231043.09375  \n",
       "3    661782.93750  \n",
       "4    601956.43750  \n",
       "..            ...  \n",
       "264  517651.34375  \n",
       "265  677358.06250  \n",
       "266  425808.43750  \n",
       "267  530970.68750  \n",
       "268  483920.34375  \n",
       "\n",
       "[269 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_location='/home/salnabulsi/coat-of-arms/data/cropped_coas/out_valid'\n",
    "# data_location='/home/salnabulsi/coat-of-arms/data/cropped_coas/out'\n",
    "# data_location='/Users/salnabulsi/tub/coat-of-arms/data/cropped_coas/out_valid'\n",
    "\n",
    "data_location='/Users/salnabulsi/tub/coat-of-arms/data/cropped_coas/out'\n",
    "test_caption_file  = data_location + '/test_real_captions_psumsq.txt'\n",
    "root_folder_images = data_location + '/images'\n",
    "\n",
    "df = pd.read_csv(test_caption_file)\n",
    "\n",
    "print(\"There are {} test images\".format(len(df)))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7a088",
   "metadata": {},
   "source": [
    "## Get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a7a6efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, criterion = get_new_model(hyper_params, \n",
    "                                            learning_rate, \n",
    "                                            ignored_idx, \n",
    "                                            drop_prob,\n",
    "                                            device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3ef4570",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1\n",
    "!export CUDA_VISIBLE_DEVICES=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b5fc2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# BATCH_SIZE = 5\n",
    "NUM_WORKER = 2 #### this needs multi-core\n",
    "freq_threshold = 5\n",
    "batch_size = 256\n",
    "\n",
    "# 30 minutes to create those, as it's baseline, i ran it several times and it's the same\n",
    "vocab = Vocabulary(freq_threshold)\n",
    "vocab.stoi = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'lion': 4, 'rampant': 5, 'passt': 6, 'guard': 7, 'head': 8, 'lions': 9, 'cross': 10, 'moline': 11, 'patonce': 12, 'eagle': 13, 'doubleheaded': 14, 'eagles': 15, 'a': 16, 'b': 17, 'o': 18, 's': 19, 'g': 20, 'e': 21, 'v': 22, '1': 23, '2': 24, '3': 25, '4': 26, '5': 27, '6': 28, '7': 29, '8': 30, '9': 31, '10': 32, '11': 33, 'border': 34, '&': 35}\n",
    "vocab.itos = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>', 4: 'lion', 5: 'rampant', 6: 'passt', 7: 'guard', 8: 'head', 9: 'lions', 10: 'cross', 11: 'moline', 12: 'patonce', 13: 'eagle', 14: 'doubleheaded', 15: 'eagles', 16: 'a', 17: 'b', 18: 'o', 19: 's', 20: 'g', 21: 'e', 22: 'v', 23: '1', 24: '2', 25: '3', 26: '4', 27: '5', 28: '6', 29: '7', 30: '8', 31: '9', 32: '10', 33: '11', 34: 'border', 35: '&'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a7dd841",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/salnabulsi/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/salnabulsi/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/Users/salnabulsi/tub/coat-of-arms/notebooks/../src/baseline/caps_collate.py\", line 35, in __call__\n    imgs    = torch.cat(imgs,dim=0)\nRuntimeError: Sizes of tensors must match except in dimension 0. Got 627 and 315 in dimension 2 (The offending index is 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0d/kx07xpsn40v0mbjthb6sbc5h0000gq/T/ipykernel_33419/1268398695.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m test_loader, test_dataset = init_testing_model(test_caption_file, \n\u001b[0m\u001b[1;32m      2\u001b[0m                                                \u001b[0mroot_folder_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                                \u001b[0mNUM_WORKER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tub/coat-of-arms/notebooks/../src/baseline/coa_model.py\u001b[0m in \u001b[0;36minit_testing_model\u001b[0;34m(test_caption_file, root_folder_images, num_worker, vocab, batch_size, device, pin_memory, img_h, img_w)\u001b[0m\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_h\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_h\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mimg_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tub/coat-of-arms/notebooks/../src/baseline/data_loader.py\u001b[0m in \u001b[0;36mget_mean\u001b[0;34m(train_dataset, train_loader, img_h, img_w)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# the batch[0] contains the images, batch[1] contains labels and 2 contains pixels values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mtotal_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1083\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1085\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/salnabulsi/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/salnabulsi/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/Users/salnabulsi/tub/coat-of-arms/notebooks/../src/baseline/caps_collate.py\", line 35, in __call__\n    imgs    = torch.cat(imgs,dim=0)\nRuntimeError: Sizes of tensors must match except in dimension 0. Got 627 and 315 in dimension 2 (The offending index is 1)\n"
     ]
    }
   ],
   "source": [
    "test_loader, test_dataset = init_testing_model(test_caption_file, \n",
    "                                               root_folder_images, \n",
    "                                               NUM_WORKER,\n",
    "                                               vocab,\n",
    "                                               batch_size,\n",
    "                                               device, \n",
    "                                               pin_memory=False) \n",
    "#                                                ,img_h=623, img_w=597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5341979",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_model(model, criterion,test_loader, test_dataset, vocab_size, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0d8887",
   "metadata": {},
   "source": [
    "## Visualizing the attentions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804520ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "test_rand_image(model,test_dataset,test_loader,device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
