{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5cdbcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto-load when code changes outside\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext pyinstrument\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12fa6a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from src.baseline.noise import Noise\n",
    "from src.utils import plot_image, plot_im, save_im\n",
    "\n",
    "from src.baseline.data_loader import get_loader, get_mean, get_std\n",
    "from src.baseline.vocabulary import Vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1683cb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location='/home/space/datasets/COA/generated-single-simple/'\n",
    "root_folder_images = data_location + '/res_images224x224/'\n",
    "caption_file  = data_location + '/captions_psumsq.txt224x224'\n",
    "\n",
    "\n",
    "df = pd.read_csv(caption_file)\n",
    "\n",
    "train_annotation_file = data_location + '/train_captions_psumsq.txt224x224'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "952099d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKER = 2\n",
    "freq_threshold = 5\n",
    "batch_size = 3\n",
    "\n",
    "# 30 minutes to create those, as it's baseline, i ran it several times and it's the same\n",
    "vocab = Vocabulary(freq_threshold)\n",
    "vocab.stoi = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'lion': 4, 'rampant': 5, 'passt': 6, 'guard': 7, 'head': 8, 'lions': 9, 'cross': 10, 'moline': 11, 'patonce': 12, 'eagle': 13, 'doubleheaded': 14, 'eagles': 15, 'a': 16, 'b': 17, 'o': 18, 's': 19, 'g': 20, 'e': 21, 'v': 22, '1': 23, '2': 24, '3': 25, '4': 26, '5': 27, '6': 28, '7': 29, '8': 30, '9': 31, '10': 32, '11': 33}\n",
    "vocab.itos = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>', 4: 'lion', 5: 'rampant', 6: 'passt', 7: 'guard', 8: 'head', 9: 'lions', 10: 'cross', 11: 'moline', 12: 'patonce', 13: 'eagle', 14: 'doubleheaded', 15: 'eagles', 16: 'a', 17: 'b', 18: 'o', 19: 's', 20: 'g', 21: 'e', 22: 'v', 23: '1', 24: '2', 25: '3', 26: '4', 27: '5', 28: '6', 29: '7', 30: '8', 31: '9', 32: '10', 33: '11'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81084024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = get_mean(train_dataset, train_loader, 224, 224)\n",
    "# std = get_std(train_dataset, train_loader, mean, 224, 224)\n",
    "# mean, std\n",
    "\n",
    "\n",
    "# Using already calculated mean and std in generated-data-api-single dataset, the mean=0.28803130984306335 and std=0.28803130984306335 @ Time = 09:41:35\n",
    "mean,std = (torch.tensor(0.288031), torch.tensor(0.2880313))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aca811fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image_79.png', 'image_123.png', 'image_203.png']\n",
      "-----------\n",
      "['image_145.png', 'image_291.png', 'image_0.png']\n",
      "-----------\n",
      "['image_149.png', 'image_223.png', 'image_163.png']\n",
      "-----------\n",
      "['image_215.png', 'image_348.png', 'image_335.png']\n",
      "-----------\n",
      "['image_65.png', 'image_241.png', 'image_293.png']\n",
      "-----------\n",
      "['image_27.png', 'image_63.png', 'image_124.png']\n",
      "-----------\n",
      "['image_47.png', 'image_153.png', 'image_329.png']\n",
      "-----------\n",
      "['image_109.png', 'image_19.png', 'image_164.png']\n",
      "-----------\n",
      "['image_102.png', 'image_354.png', 'image_342.png']\n",
      "-----------\n",
      "['image_308.png', 'image_142.png', 'image_269.png']\n",
      "-----------\n",
      "['image_21.png', 'image_191.png', 'image_315.png']\n",
      "-----------\n",
      "['image_262.png', 'image_88.png', 'image_286.png']\n",
      "-----------\n",
      "['image_144.png', 'image_22.png', 'image_143.png']\n",
      "-----------\n",
      "['image_91.png', 'image_141.png', 'image_351.png']\n",
      "-----------\n",
      "['image_254.png', 'image_252.png', 'image_35.png']\n",
      "-----------\n",
      "['image_186.png', 'image_278.png', 'image_222.png']\n",
      "-----------\n",
      "['image_213.png', 'image_17.png', 'image_77.png']\n",
      "-----------\n",
      "['image_267.png', 'image_103.png', 'image_287.png']\n",
      "-----------\n",
      "['image_352.png', 'image_117.png', 'image_204.png']\n",
      "-----------\n",
      "['image_175.png', 'image_304.png', 'image_122.png']\n",
      "-----------\n",
      "['image_229.png', 'image_36.png', 'image_288.png']\n",
      "-----------\n",
      "['image_180.png', 'image_238.png', 'image_357.png']\n",
      "-----------\n",
      "['image_75.png', 'image_199.png', 'image_39.png']\n",
      "-----------\n",
      "['image_30.png', 'image_52.png', 'image_5.png']\n",
      "-----------\n",
      "['image_12.png', 'image_323.png', 'image_24.png']\n",
      "-----------\n",
      "['image_189.png', 'image_57.png', 'image_4.png']\n",
      "-----------\n",
      "['image_78.png', 'image_58.png', 'image_83.png']\n",
      "-----------\n",
      "['image_115.png', 'image_260.png', 'image_177.png']\n",
      "-----------\n",
      "['image_84.png', 'image_6.png', 'image_192.png']\n",
      "-----------\n",
      "['image_202.png', 'image_178.png', 'image_277.png']\n",
      "-----------\n",
      "['image_187.png', 'image_18.png', 'image_345.png']\n",
      "-----------\n",
      "['image_259.png', 'image_105.png', 'image_93.png']\n",
      "-----------\n",
      "['image_274.png', 'image_172.png', 'image_312.png']\n",
      "-----------\n",
      "['image_216.png', 'image_154.png', 'image_343.png']\n",
      "-----------\n",
      "['image_140.png', 'image_185.png', 'image_217.png']\n",
      "-----------\n",
      "['image_56.png', 'image_45.png', 'image_197.png']\n",
      "-----------\n",
      "['image_64.png', 'image_336.png', 'image_264.png']\n",
      "-----------\n",
      "['image_3.png', 'image_276.png', 'image_55.png']\n",
      "-----------\n",
      "['image_290.png', 'image_307.png', 'image_325.png']\n",
      "-----------\n",
      "['image_257.png', 'image_148.png', 'image_165.png']\n",
      "-----------\n",
      "['image_282.png', 'image_297.png', 'image_150.png']\n",
      "-----------\n",
      "['image_157.png', 'image_298.png', 'image_50.png']\n",
      "-----------\n",
      "['image_159.png', 'image_225.png', 'image_152.png']\n",
      "-----------\n",
      "['image_344.png', 'image_139.png', 'image_289.png']\n",
      "-----------\n",
      "['image_134.png', 'image_226.png', 'image_227.png']\n",
      "-----------\n",
      "['image_253.png', 'image_285.png', 'image_201.png']\n",
      "-----------\n",
      "['image_268.png', 'image_183.png', 'image_184.png']\n",
      "-----------\n",
      "['image_207.png', 'image_42.png', 'image_9.png']\n",
      "-----------\n",
      "['image_29.png', 'image_62.png', 'image_107.png']\n",
      "-----------\n",
      "['image_243.png', 'image_245.png', 'image_170.png']\n",
      "-----------\n",
      "['image_26.png', 'image_166.png', 'image_113.png']\n",
      "-----------\n",
      "['image_80.png', 'image_190.png', 'image_355.png']\n",
      "-----------\n",
      "['image_54.png', 'image_200.png', 'image_7.png']\n",
      "-----------\n",
      "['image_181.png', 'image_112.png', 'image_81.png']\n",
      "-----------\n",
      "['image_219.png', 'image_48.png', 'image_228.png']\n",
      "-----------\n",
      "['image_74.png', 'image_14.png', 'image_121.png']\n",
      "-----------\n",
      "['image_119.png', 'image_38.png', 'image_116.png']\n",
      "-----------\n",
      "['image_255.png', 'image_206.png', 'image_70.png']\n",
      "-----------\n",
      "['image_67.png', 'image_236.png', 'image_265.png']\n",
      "-----------\n",
      "['image_235.png', 'image_305.png', 'image_248.png']\n",
      "-----------\n",
      "['image_95.png', 'image_176.png', 'image_147.png']\n",
      "-----------\n",
      "['image_258.png', 'image_108.png', 'image_72.png']\n",
      "-----------\n",
      "['image_214.png', 'image_244.png', 'image_273.png']\n",
      "-----------\n",
      "['image_51.png', 'image_333.png', 'image_218.png']\n",
      "-----------\n",
      "['image_310.png', 'image_316.png', 'image_188.png']\n",
      "-----------\n",
      "['image_232.png', 'image_337.png', 'image_281.png']\n",
      "-----------\n",
      "['image_131.png', 'image_167.png', 'image_85.png']\n",
      "-----------\n",
      "['image_221.png', 'image_23.png', 'image_251.png']\n",
      "-----------\n",
      "['image_155.png', 'image_169.png', 'image_220.png']\n",
      "-----------\n",
      "['image_71.png', 'image_37.png', 'image_138.png']\n",
      "-----------\n",
      "['image_133.png', 'image_96.png', 'image_313.png']\n",
      "-----------\n",
      "['image_146.png', 'image_314.png', 'image_270.png']\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "height, width = 224, 224\n",
    "import random\n",
    "\n",
    "train_transform_list = [\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(10),\n",
    "    T.RandomCrop(224),\n",
    "    T.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5)),\n",
    "    T.ColorJitter(brightness=.5, hue=.3)\n",
    "]\n",
    "\n",
    "# Use RandomApply to apply the transform randomly to some of the images\n",
    "# print(random_tran)\n",
    "# print('00000000000')\n",
    "transform_with_random = T.Compose([\n",
    "    T.Resize((height, width)), # mandetory                  \n",
    "    random.choice(train_transform_list),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std), # mandetory \n",
    "    Noise(0.1, 0.05), # this should come at the end\n",
    "])\n",
    "\n",
    "# print(transform_with_random)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader, train_dataset = get_loader(\n",
    "    root_folder=root_folder_images,\n",
    "    annotation_file=train_annotation_file,\n",
    "    transform=transform_with_random,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0,\n",
    "    vocab=vocab,\n",
    "    device=device,\n",
    "    pin_memory=False\n",
    ")\n",
    "\n",
    "for idx, (imgs, correct_caps,_,_,image_file_names) in enumerate(iter(train_loader)):\n",
    "    print(image_file_names)\n",
    "    images, captions = imgs.to(device), correct_caps.to(device)\n",
    "    print('-----------')\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bf7968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7249b536",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
