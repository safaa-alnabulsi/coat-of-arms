{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5cdbcf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The pyinstrument extension is already loaded. To reload it, use:\n",
      "  %reload_ext pyinstrument\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# auto-load when code changes outside\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext pyinstrument\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12fa6a61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "module functions cannot set METH_CLASS or METH_STATIC",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1269096/4256805095.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msleep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNoise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coat-of-arms/notebooks/../src/baseline/noise.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mNoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \"\"\"Adds gaussian noise to a tensor.\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.thesis-py38/lib/python3.8/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: module functions cannot set METH_CLASS or METH_STATIC"
     ]
    }
   ],
   "source": [
    "#imports \n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx as onnx\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "from src.baseline.noise import Noise\n",
    "from src.baseline.vocabulary import Vocabulary\n",
    "from src.baseline.data_loader import get_loader, get_loaders, get_mean, get_std\n",
    "from src.baseline.coa_model import save_model, load_model, get_new_model, validate_model, train_model, train_validate_test_split\n",
    "from src.utils import print_time, zip_dir_to_file, unzip_file_to_dir, list_of_tensors_to_numpy_arr\n",
    "from src.pytorchtools import EarlyStopping, EarlyStoppingAccuracy\n",
    "from src.accuracy import Accuracy\n",
    "\n",
    "from pyinstrument import Profiler\n",
    "from datetime import datetime\n",
    "from shutil import copyfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814ad5d2",
   "metadata": {},
   "source": [
    "## Torch data-loader\n",
    "https://www.kaggle.com/mdteach/torch-data-loader-flicker-8k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587ed02f",
   "metadata": {},
   "source": [
    "# Split Data into Training/Test datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c61fc8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 432 train images\n",
      "There are 144 val images\n",
      "There are 144 test images\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# data_location = '/home/space/datasets/COA/generated-data-api'\n",
    "# data_location =  '/home/space/datasets/COA/generated-data-api-small'\n",
    "# data_location =  '../baseline-gen-data/large'\n",
    "# data_location =  '../baseline-gen-data/medium'\n",
    "# data_location =  '../baseline-gen-data/small'\n",
    "data_location = '/home/space/datasets/COA/generated-data-api-single'\n",
    "\n",
    "caption_file = data_location + '/captions-psumsq.txt'\n",
    "# caption_file = data_location + '/captions.txt'\n",
    "root_folder_images = data_location + '/images/'\n",
    "# root_folder_images = data_location + '/res_images/'\n",
    "\n",
    "df = pd.read_csv(caption_file)\n",
    "\n",
    "# train, validate, test = train_validate_test_split(df, train_percent=.6, validate_percent=.2, seed=None)\n",
    "\n",
    "\n",
    "train_annotation_file = data_location + '/train_captions_psumsq.txt'\n",
    "val_annotation_file  = data_location + '/val_captions_psumsq.txt'\n",
    "test_annotation_file  = data_location + '/test_captions_psumsq.txt'\n",
    "\n",
    "# train.to_csv(train_annotation_file, sep=',',index=False)\n",
    "# test.to_csv(test_annotation_file, sep=',',index=False)\n",
    "# validate.to_csv(val_annotation_file, sep=',',index=False)\n",
    "\n",
    "\n",
    "# print(\"There are {} total images\".format(len(df)))\n",
    "\n",
    "df1 = pd.read_csv(train_annotation_file)\n",
    "print(\"There are {} train images\".format(len(df1)))\n",
    "\n",
    "df2 = pd.read_csv(val_annotation_file)\n",
    "print(\"There are {} val images\".format(len(df2)))\n",
    "\n",
    "df3 = pd.read_csv(test_annotation_file)\n",
    "print(\"There are {} test images\".format(len(df3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e779ff1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: image_1.png A A lion 14548.7998046875 13190.97265625\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mpimg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1269096/309948943.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_folder_images\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Caption:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mpimg' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(1,2):\n",
    "    image_path = root_folder_images + df.iloc[i,0]\n",
    "    print(\"Caption:\", df.iloc[i,0], df.iloc[i,1], df.iloc[i,2],df.iloc[i,3])\n",
    "    img=mpimg.imread(image_path)\n",
    "    print(img.shape)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25fd47a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0\n",
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f477a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf67d490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a13d222",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1e7cfd",
   "metadata": {},
   "source": [
    "# Image Captioning With Attention - Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae69600a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'lion': 4, 'rampant': 5, 'passt': 6, 'guard': 7, 'head': 8, 'lions': 9, 'cross': 10, 'moline': 11, 'patonce': 12, 'eagle': 13, 'doubleheaded': 14, 'eagles': 15, 'a': 16, 'b': 17, 'o': 18, 's': 19, 'g': 20, 'e': 21, 'v': 22, '1': 23, '2': 24, '3': 25, '4': 26, '5': 27, '6': 28, '7': 29, '8': 30, '9': 31, '10': 32, '11': 33, 'border': 34, '&': 35}\n",
      "[16, 4, 5]\n",
      "{0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>', 4: 'lion', 5: 'rampant', 6: 'passt', 7: 'guard', 8: 'head', 9: 'lions', 10: 'cross', 11: 'moline', 12: 'patonce', 13: 'eagle', 14: 'doubleheaded', 15: 'eagles', 16: 'a', 17: 'b', 18: 'o', 19: 's', 20: 'g', 21: 'e', 22: 'v', 23: '1', 24: '2', 25: '3', 26: '4', 27: '5', 28: '6', 29: '7', 30: '8', 31: '9', 32: '10', 33: '11', 34: 'border', 35: '&'}\n"
     ]
    }
   ],
   "source": [
    "from src.baseline.vocabulary import Vocabulary\n",
    "\n",
    "# BATCH_SIZE = 5\n",
    "NUM_WORKER = 2 #### this needs multi-core\n",
    "#NUM_WORKER = 0 #### this needs multi-core\n",
    "\n",
    "#testing the vicab class \n",
    "v = Vocabulary(freq_threshold=1)\n",
    "\n",
    "v.build_vocab([ 'lion','lion rampant', 'lion passt', 'lion passt guard', \"lion's head\",\n",
    "                'lions','lions rampant', 'lions passt', 'lions passt guard',\n",
    "               'cross', 'cross moline', 'cross patonce',\n",
    "               'eagle', 'eagle doubleheaded', 'eagles', 'eagles doubleheaded',\n",
    "              'A', 'B', 'O', 'S', 'G', 'E', 'V',\n",
    "              '1', '2', '3', '4', '5', '6', '7', '8', '9', '10','11',\n",
    "              'border', '&'])\n",
    "\n",
    "print(v.stoi)\n",
    "print(v.numericalize(\"A lion rampant\"))\n",
    "print(v.itos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5cc0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_threshold = 5\n",
    "# # 30 minutes to create those, as it's baseline, i ran it several times and it's the same\n",
    "vocab = Vocabulary(freq_threshold)\n",
    "vocab.stoi = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'lion': 4, 'rampant': 5, 'passt': 6, 'guard': 7, 'head': 8, 'lions': 9, 'cross': 10, 'moline': 11, 'patonce': 12, 'eagle': 13, 'doubleheaded': 14, 'eagles': 15, 'a': 16, 'b': 17, 'o': 18, 's': 19, 'g': 20, 'e': 21, 'v': 22, '1': 23, '2': 24, '3': 25, '4': 26, '5': 27, '6': 28, '7': 29, '8': 30, '9': 31, '10': 32, '11': 33, 'border': 34, '&': 35}\n",
    "vocab.itos = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>', 4: 'lion', 5: 'rampant', 6: 'passt', 7: 'guard', 8: 'head', 9: 'lions', 10: 'cross', 11: 'moline', 12: 'patonce', 13: 'eagle', 14: 'doubleheaded', 15: 'eagles', 16: 'a', 17: 'b', 18: 'o', 19: 's', 20: 'g', 21: 'e', 22: 'v', 23: '1', 24: '2', 25: '3', 26: '4', 27: '5', 28: '6', 29: '7', 30: '8', 31: '9', 32: '10', 33: '11', 34: 'border', 35: '&'}\n",
    "\n",
    "# old before extending to multi object, plural and border\n",
    "# vocab.stoi = {'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, '<UNK>': 3, 'g': 4, 'v': 5, 'b': 6, 'cross': 7, 'lion': 8, 'passt': 9, 's': 10, 'a': 11, 'eagle': 12, 'o': 13, 'doubleheaded': 14, \"'s\": 15, 'head': 16, 'patonce': 17, 'moline': 18, 'guard': 19, 'rampant': 20}\n",
    "# vocab.itos = {0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: '<UNK>', 4: 'g', 5: 'v', 6: 'b', 7: 'cross', 8: 'lion', 9: 'passt', 10: 's', 11: 'a', 12: 'eagle', 13: 'o', 14: 'doubleheaded', 15: \"'s\", 16: 'head', 17: 'patonce', 18: 'moline', 19: 'guard', 20: 'rampant'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d3afbe",
   "metadata": {},
   "source": [
    "## Calcualte the mean and std of training dataset\n",
    "\n",
    "https://deeplizard.com/learn/video/lu7TCu7HeYc\n",
    "\n",
    "https://discuss.pytorch.org/t/understanding-transform-normalize/21730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74295564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------------------ \n",
      " before DataLoader @ Time = 17:32:33\n",
      "\n",
      "  _     ._   __/__   _ _  _  _ _/_   Recorded: 17:32:33  Samples:  6\n",
      " /_//_/// /_\\ / //_// / //_'/ //     Duration: 0.007     CPU time: 0.007\n",
      "/   _/                      v4.1.1\n",
      "\n",
      "Program: /Users/salnabulsi/miniconda/envs/thesis-py38/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/salnabulsi/Library/Jupyter/runtime/kernel-c80ef6fb-e1f4-4fc6-9b6f-b0f883c64b35.json\n",
      "\n",
      "0.006 run_code  IPython/core/interactiveshell.py:3361\n",
      "└─ 0.006 <cell line: 5>  ../../../../var/folders/0d/kx07xpsn40v0mbjthb6sbc5h0000gq/T/ipykernel_65910/810534119.py:5\n",
      "   └─ 0.006 get_loader  src/baseline/data_loader.py:11\n",
      "      └─ 0.006 __init__  src/baseline/coa_dataset.py:15\n",
      "         ├─ 0.004 wrapper  pandas/util/_decorators.py:302\n",
      "         │     [20 frames hidden]  pandas\n",
      "         └─ 0.002 __getitem__  pandas/core/frame.py:3463\n",
      "               [11 frames hidden]  pandas, <built-in>\n",
      "\n",
      "\n",
      "\n",
      " ------------------------ \n",
      " after DataLoader @ Time = 17:32:33\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print_time('\\n ------------------------ \\n before DataLoader')\n",
    "profiler = Profiler(async_mode='disabled')\n",
    "\n",
    "profiler.start()\n",
    "train_loader, train_dataset = get_loader(\n",
    "    root_folder=root_folder_images,\n",
    "    annotation_file=train_annotation_file,\n",
    "    transform=None,  # <=======================\n",
    "    num_workers=NUM_WORKER,\n",
    "    vocab=vocab,\n",
    "    batch_size=256,\n",
    "    device=device,\n",
    "    pin_memory=False,\n",
    "    calc_mean=True\n",
    ")\n",
    "\n",
    "profiler.stop()\n",
    "\n",
    "profiler.print()\n",
    "\n",
    "print_time('\\n ------------------------ \\n after DataLoader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23b4c10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------------------ \n",
      " before get_mean @ Time = 17:32:34\n",
      "mean: tensor(6.7968)\n",
      "------------------------ \n",
      " after get_mean @ Time = 17:32:54\n",
      "\n",
      "  _     ._   __/__   _ _  _  _ _/_   Recorded: 17:32:33  Samples:  61\n",
      " /_//_/// /_\\ / //_// / //_'/ //     Duration: 19.883    CPU time: 0.091\n",
      "/   _/                      v4.1.1\n",
      "\n",
      "Program: /Users/salnabulsi/miniconda/envs/thesis-py38/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/salnabulsi/Library/Jupyter/runtime/kernel-c80ef6fb-e1f4-4fc6-9b6f-b0f883c64b35.json\n",
      "\n",
      "19.882 run_ast_nodes  IPython/core/interactiveshell.py:3237\n",
      "└─ 19.878 run_code  IPython/core/interactiveshell.py:3361\n",
      "   └─ 19.867 <cell line: 7>  ../../../../var/folders/0d/kx07xpsn40v0mbjthb6sbc5h0000gq/T/ipykernel_65910/2254507660.py:7\n",
      "      └─ 19.866 get_mean  src/baseline/data_loader.py:57\n",
      "         └─ 19.715 __next__  torch/utils/data/dataloader.py:526\n",
      "               [31 frames hidden]  torch, multiprocessing, selectors, <b...\n",
      "                  9.591 poll.poll  <built-in>:0\n",
      "                  9.705 poll.poll  <built-in>:0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# img_h,img_w = 500,500\n",
    "img_h,img_w = 100,100\n",
    "\n",
    "print_time('\\n ------------------------ \\n before get_mean')\n",
    "\n",
    "profiler.start()\n",
    "mean = get_mean(train_dataset, train_loader, img_h , img_w)\n",
    "print('mean:', mean)\n",
    "profiler.stop()\n",
    "\n",
    "print_time('------------------------ \\n after get_mean')\n",
    "profiler.print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6722cc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ------------------------ \n",
      " before get_std @ Time = 17:32:54\n",
      "tensor(60238232.)\n",
      "tensor(87882664.)\n",
      "tensor(-5.3708e+08)\n",
      "12930000\n",
      "std: tensor(nan)\n",
      "------------------------ \n",
      " after get_std @ Time = 17:33:07\n",
      "\n",
      "  _     ._   __/__   _ _  _  _ _/_   Recorded: 17:32:33  Samples:  94\n",
      " /_//_/// /_\\ / //_// / //_'/ //     Duration: 33.057    CPU time: 0.142\n",
      "/   _/                      v4.1.1\n",
      "\n",
      "Program: /Users/salnabulsi/miniconda/envs/thesis-py38/lib/python3.8/site-packages/ipykernel_launcher.py -f /Users/salnabulsi/Library/Jupyter/runtime/kernel-c80ef6fb-e1f4-4fc6-9b6f-b0f883c64b35.json\n",
      "\n",
      "33.055 run_ast_nodes  IPython/core/interactiveshell.py:3237\n",
      "└─ 33.051 run_code  IPython/core/interactiveshell.py:3361\n",
      "   ├─ 19.867 <cell line: 7>  ../../../../var/folders/0d/kx07xpsn40v0mbjthb6sbc5h0000gq/T/ipykernel_65910/2254507660.py:7\n",
      "   │  └─ 19.866 get_mean  src/baseline/data_loader.py:57\n",
      "   │     └─ 19.715 __next__  torch/utils/data/dataloader.py:526\n",
      "   │           [31 frames hidden]  torch, multiprocessing, selectors, <b...\n",
      "   │              9.591 poll.poll  <built-in>:0\n",
      "   │              9.705 poll.poll  <built-in>:0\n",
      "   └─ 13.171 <cell line: 3>  ../../../../var/folders/0d/kx07xpsn40v0mbjthb6sbc5h0000gq/T/ipykernel_65910/3271053047.py:3\n",
      "      └─ 13.171 get_std  src/baseline/data_loader.py:74\n",
      "         └─ 13.128 __next__  torch/utils/data/dataloader.py:526\n",
      "               [23 frames hidden]  torch, multiprocessing, selectors, <b...\n",
      "                  9.693 poll.poll  <built-in>:0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_time('\\n ------------------------ \\n before get_std')\n",
    "profiler.start()\n",
    "std = get_std(train_dataset, train_loader, mean, img_h , img_w)\n",
    "print('std:', std)\n",
    "\n",
    "profiler.stop()\n",
    "\n",
    "print_time('------------------------ \\n after get_std')\n",
    "profiler.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a51a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the transform to be applied\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(226),      # to check why?               \n",
    "    T.RandomCrop(224),  # to check why?               \n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean, std),\n",
    "    Noise(0.1, 0.05)\n",
    "])\n",
    "\n",
    "# transform\n",
    "# img_location = root_folder_images + '/image_140.png' \n",
    "# img = Image.open(img_location).convert(\"RGB\")\n",
    "# trans   = T.ToTensor()\n",
    "# img     = trans(img)\n",
    "# psum    = img.sum()\n",
    "# psumx    = img.sum(axis=[1,2])t\n",
    "# psum_sq = (img ** 2)\n",
    "# img.size(), psum, psumx, psumx.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3e2222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing the dataloader @ Time = 17:33:07\n",
      "initing train loader\n",
      "-------------\n",
      "initing val loader\n",
      "-------------\n",
      "initing test loader\n",
      "finished writing the dataloader @ Time = 17:33:07\n"
     ]
    }
   ],
   "source": [
    "#Initiate the Dataset and Dataloader\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "print_time('writing the dataloader')\n",
    "\n",
    "train_loader, val_loader, test_loader, train_dataset, val_dataset, test_dataset = get_loaders(\n",
    "    root_folder=root_folder_images,\n",
    "    train_annotation_file=train_annotation_file,\n",
    "    val_annotation_file=val_annotation_file,\n",
    "    test_annotation_file=test_annotation_file,\n",
    "    transform=transform,\n",
    "    num_workers=NUM_WORKER,\n",
    "    vocab=vocab,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    pin_memory=False\n",
    ")\n",
    "len(train_loader), len(val_loader), len(test_loader), len(train_dataset), len(val_dataset), len(test_dataset)\n",
    "print_time('finished writing the dataloader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc829f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<PAD>': 0,\n",
       " '<SOS>': 1,\n",
       " '<EOS>': 2,\n",
       " '<UNK>': 3,\n",
       " 'lion': 4,\n",
       " 'rampant': 5,\n",
       " 'passt': 6,\n",
       " 'guard': 7,\n",
       " 'head': 8,\n",
       " 'lions': 9,\n",
       " 'cross': 10,\n",
       " 'moline': 11,\n",
       " 'patonce': 12,\n",
       " 'eagle': 13,\n",
       " 'doubleheaded': 14,\n",
       " 'eagles': 15,\n",
       " 'a': 16,\n",
       " 'b': 17,\n",
       " 'o': 18,\n",
       " 's': 19,\n",
       " 'g': 20,\n",
       " 'e': 21,\n",
       " 'v': 22,\n",
       " '1': 23,\n",
       " '2': 24,\n",
       " '3': 25,\n",
       " '4': 26,\n",
       " '5': 27,\n",
       " '6': 28,\n",
       " '7': 29,\n",
       " '8': 30,\n",
       " '9': 31,\n",
       " '10': 32,\n",
       " '11': 33,\n",
       " 'border': 34,\n",
       " '&': 35}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bb6b3a",
   "metadata": {},
   "source": [
    "# Defining the Model Architecture\n",
    "\n",
    "Model is seq2seq model. In the **encoder** pretrained ResNet model is used to extract the features. Decoder, is the implementation of the Bahdanau Attention Decoder. In the decoder model **LSTM cell**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332143d9",
   "metadata": {},
   "source": [
    "https://blog.floydhub.com/attention-mechanism/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d939ae8d",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5808f315",
   "metadata": {},
   "source": [
    "### Setting Hypperparameter and Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "556bf00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.vocab.stoi[\"<PAD>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f14a2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(train_dataset.vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5fe96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "embed_size=300\n",
    "vocab_size = len(train_dataset.vocab)\n",
    "attention_dim=256\n",
    "\n",
    "# Trying on a smaller model\n",
    "# https://pytorch.org/vision/stable/models/resnet.html\n",
    "# encoder_dim=2048  ### resnet50\n",
    "encoder_dim=512     ### resnet34 & resnet18\n",
    "decoder_dim=512\n",
    "\n",
    "learning_rate = 3e-4\n",
    "drop_prob=0.3\n",
    "ignored_idx = train_dataset.vocab.stoi[\"<PAD>\"]\n",
    "\n",
    "hyper_params = {'embed_size': embed_size,\n",
    "                'attention_dim': attention_dim,\n",
    "                'encoder_dim': encoder_dim,\n",
    "                'decoder_dim': decoder_dim,\n",
    "                'vocab_size': vocab_size\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47a69030",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#initialize new model, loss etc\n",
    "model, optimizer, criterion = get_new_model(hyper_params, learning_rate, \n",
    "                                            ignored_idx, drop_prob, device, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27412a80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderDecoder(\n",
      "  (encoder): EncoderCNN(\n",
      "    (resnet): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      (4): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (6): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (7): Sequential(\n",
      "        (0): BasicBlock(\n",
      "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (downsample): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (1): BasicBlock(\n",
      "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): DecoderRNN(\n",
      "    (embedding): Embedding(36, 300)\n",
      "    (attention): Attention(\n",
      "      (W): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (U): Linear(in_features=512, out_features=256, bias=True)\n",
      "      (A): Linear(in_features=256, out_features=1, bias=True)\n",
      "    )\n",
      "    (init_h): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (init_c): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (lstm_cell): LSTMCell(812, 512)\n",
      "    (f_beta): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (fcn): Linear(in_features=512, out_features=36, bias=True)\n",
      "    (drop): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "# summary(model, (3, 224, 224))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1519bea1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m images,_,_,_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(val_loader))\n\u001b[1;32m      2\u001b[0m img \u001b[38;5;241m=\u001b[39m images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m      3\u001b[0m img1 \u001b[38;5;241m=\u001b[39m images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone()\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "images,_,_,_ = next(iter(val_loader))\n",
    "img = images[0].detach().clone()\n",
    "img1 = images[0].detach().clone()\n",
    "caps,alphas = get_caps_from(model, test_dataset, img.unsqueeze(0),device)\n",
    "caps,alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4295d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model(images) # Give dummy batch to forward().\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de13c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "\n",
    "make_dot(yhat, params=dict(list(model.named_parameters()))).render(\"rnn_torchviz\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781b80e8",
   "metadata": {},
   "source": [
    "## Training Job from above configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53074260",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1\n",
    "!export CUDA_VISIBLE_DEVICES=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b47431",
   "metadata": {},
   "source": [
    "## Train the Model using Early Stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1552fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device is cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|                               | 0/2 [00:32<?, ?batch/s, Train loss (in progress)=nan]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "No shield color found in this label: \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\"\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "No shield color found in this label: \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████████| 2/2 [02:08<00:00, 59.15s/batch, Train loss (in progress)=nan]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "No shield color found in this label: \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|███████████████████████| 2/2 [02:08<00:00, 64.37s/batch, Train loss (in progress)=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1/10] train_loss: nan , valid_loss: nan , accuracy: 0.00000\n",
      "Accuracy increased (0.000000 --> 0.000000).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:   0%|                               | 0/2 [00:32<?, ?batch/s, Train loss (in progress)=nan]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "No shield color found in this label: \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\"\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "No shield color found in this label: \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|███████████████████████| 2/2 [02:05<00:00, 58.03s/batch, Train loss (in progress)=nan]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "label \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\" cannot be parsed. The chunk \"<PAD>\" cannot be fit into any category.\n",
      "No shield color found in this label: \"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|███████████████████████| 2/2 [02:06<00:00, 63.03s/batch, Train loss (in progress)=nan]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2/10] train_loss: nan , valid_loss: nan , accuracy: 0.00000\n",
      "Accuracy increased (0.000000 --> 0.000000).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|                               | 0/2 [00:48<?, ?batch/s, Train loss (in progress)=nan]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m timestr \u001b[38;5;241m=\u001b[39m now\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m model_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiments/run-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 14\u001b[0m model, train_loss, valid_loss, avg_acc, bleu_score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mmodel_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/tub/coat-of-arms/notebooks/../src/baseline/coa_model.py:182\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, criterion, train_dataset, train_loader, val_loader, val_dataset, vocab_size, batch_size, patience, n_epochs, device, model_folder)\u001b[0m\n\u001b[1;32m    179\u001b[0m writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_batch_loss, loss_idx_value)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# nice to have:  training accuracy\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m predicted_caption, correct_caption,caps \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m correct_caption_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(correct_caption)\n\u001b[1;32m    184\u001b[0m acc \u001b[38;5;241m=\u001b[39m Accuracy(predicted_caption,correct_caption_s)\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m~/tub/coat-of-arms/notebooks/../src/baseline/coa_model.py:56\u001b[0m, in \u001b[0;36mpredict_image\u001b[0;34m(model, image, correct_cap, dataset, device)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_image\u001b[39m(model,image, correct_cap, dataset, device):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# encode the image to be ready for prediction\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     features_tensors \u001b[38;5;241m=\u001b[39m image[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     58\u001b[0m     features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencoder(features_tensors\u001b[38;5;241m.\u001b[39mto(device))\n",
      "File \u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/tub/coat-of-arms/notebooks/../src/baseline/model.py:27\u001b[0m, in \u001b[0;36mEncoderCNN.forward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, images):\n\u001b[0;32m---> 27\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m                                    \u001b[38;5;66;03m#(batch_size,2048,7,7)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)                           \u001b[38;5;66;03m#(batch_size,7,7,2048)\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mview(features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;66;03m#(batch_size,49,2048)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torchvision/models/resnet.py:94\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     91\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[1;32m     92\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m---> 94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(out)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/nn/modules/conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 447\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/torch/nn/modules/conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    441\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    442\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "batch_size = 256\n",
    "n_epochs = 10\n",
    "\n",
    "# early stopping patience; how long to wait after last time validation loss improved.\n",
    "patience = 5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f'device is {device}')\n",
    "\n",
    "now = datetime.now() # current date and time\n",
    "timestr = now.strftime(\"%m-%d-%Y-%H:%M:%S\")\n",
    "model_folder = f\"experiments/run-{timestr}\"\n",
    "\n",
    "model, train_loss, valid_loss, avg_acc, bleu_score = train_model(model, \n",
    "                                                                 optimizer, \n",
    "                                                                 criterion, \n",
    "                                                                 train_dataset, \n",
    "                                                                 train_loader, \n",
    "                                                                 val_loader, \n",
    "                                                                 val_dataset, \n",
    "                                                                 vocab_size, \n",
    "                                                                 batch_size, \n",
    "                                                                 patience, \n",
    "                                                                 n_epochs, \n",
    "                                                                 device,\n",
    "                                                                 model_folder)\n",
    "\n",
    "# CPU - locally\n",
    "# ============================================================================\n",
    "# Time comparison when exacuting locally for the medium dataset (720 image)\n",
    "# ============================================================================\n",
    "# resnet18 speed on 1 epoc = 02:06\n",
    "# resnet34 speed on 1 epoc = 03:56\n",
    "# resnet50 speed on 1 epoc = 05:26\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# ============================================================================\n",
    "# After resizing images to 100x100 - while loading the batchs\n",
    "# ============================================================================\n",
    "# resnet18 speed on 1 epoc = 02:11\n",
    "# resnet34 speed on 1 epoc = 04:16\n",
    "# resnet50 speed on 1 epoc = 05:41\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# ============================================================================\n",
    "# After resizing images to 100x100 - When doing it before in 14-resize-synthetic-images-to-smaller \n",
    "# ============================================================================\n",
    "# resnet18 speed on 1 epoc = 02:23\n",
    "# resnet34 speed on 1 epoc = 03:54\n",
    "# resnet50 speed on 1 epoc = 05:04\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "# changing only the embed_size from 300 to 150 with resent18 increased the time from 02:23 to 03:23 \n",
    "\n",
    "# changing only the attention_dim from 256 to 128 with resent18 increased the time from 02:23 to 03:20 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf47557",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Train loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(valid_loss)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Validation loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(avg_acc)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8687a206",
   "metadata": {},
   "source": [
    "## Visualizing the Accuracy (and loss) and the Early Stopping Checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "92731be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the loss as the network trained\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
    "\n",
    "# valid_loss_arr = list_of_tensors_to_numpy_arr(valid_loss)\n",
    "plt.plot(range(1,len(valid_loss)+1),valid_loss, label='Validation Loss')\n",
    "\n",
    "# find position of lowest validation loss\n",
    "# minposs = valid_loss.index(min(valid_loss))+1 \n",
    "# plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "# find position of lowest validation loss\n",
    "maxposs = avg_acc.index(max(avg_acc))-1 \n",
    "plt.axvline(maxposs, linestyle='--', color='r',label='Early Stopping Checkpoint - Accuracy')\n",
    "\n",
    "plt.plot(range(1,len(avg_acc)+1),avg_acc,label='Accuracy')\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "# plt.ylim(0, 0.5) # consistent scale\n",
    "# plt.xlim(0, len(train_loss)+1) # consistent scale\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('loss_plot.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0071858",
   "metadata": {},
   "source": [
    "# Test the Trained Network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6e03b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now() # current date and time\n",
    "timestr = now.strftime(\"%m.%d.%Y-%H:%M:%S\")\n",
    "\n",
    "save_model(model, optimizer, train_loss, avg_acc, f'../large-model-{timestr}.pt', hyper_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9f0783f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "ignored_idx = train_dataset.vocab.stoi[\"<PAD>\"]\n",
    "\n",
    "\n",
    "saved_model_path = '../small-model.pt'\n",
    "# saved_model_path = f'/home/space/datasets/COA/models/baseline/model-4-4.pth'\n",
    "model, optimizer, loss,criterion = load_model(saved_model_path, hyper_params, learning_rate, drop_prob, ignored_idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "50937565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a lion\n",
      "Test Acuuracy (in progress): 0.000000\n",
      "\n",
      "Test Loss (final): 0.100419\n",
      "\n",
      "Test Accuracy (Overall): 0.0%\n"
     ]
    }
   ],
   "source": [
    "# initialize lists to monitor test loss and accuracy\n",
    "test_loss = 0.0\n",
    "test_losses=[]\n",
    "accuracy_test_list=[]\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, (img, correct_cap,_) in enumerate(iter(test_loader)):\n",
    "        features = model.encoder(img.to(device))\n",
    "\n",
    "        features_tensors = img[0].detach().clone().unsqueeze(0)\n",
    "        features = model.encoder(features_tensors.to(device))\n",
    "\n",
    "        caps,_ = model.decoder.generate_caption(features, vocab=val_dataset.vocab)   \n",
    "        caps = caps[:-1]\n",
    "        predicted_caption = ' '.join(caps)\n",
    "        print(predicted_caption)\n",
    "        # compare predictions to true label\n",
    "        correct_caption = []\n",
    "        for j in correct_cap.T[0]:\n",
    "            if j.item() not in [0, 1, 2 , 3]:\n",
    "                correct_caption.append(val_dataset.vocab.itos[j.item()])\n",
    "        correct_caption_s = ' '.join(correct_caption)\n",
    "        \n",
    "        # calc metrics\n",
    "        acc_test = Accuracy(predicted_caption,correct_caption_s).get()\n",
    "        accuracy_test_list.append(acc_test)\n",
    "        print(f'Test Acuuracy (in progress): {acc_test:.6f}\\n')\n",
    "\n",
    "        # ------------------------------------------\n",
    "        # calc losses and take the average \n",
    "        image, captions = img.to(device), correct_cap.to(device)\n",
    "        outputs, _ = model(image, captions.T)\n",
    "        targets    = captions.T[:,1:] \n",
    "        loss       = criterion(outputs.view(-1, vocab_size), targets.reshape(-1))\n",
    "        test_losses.append(loss)\n",
    "\n",
    "        # ------------------------------------------\n",
    "\n",
    "# calculate and print avg test loss\n",
    "test_loss = sum(test_losses)/len(test_dataset)\n",
    "print('Test Loss (final): {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "acc_test_score = (100. * sum(accuracy_test_list) / len(accuracy_test_list))\n",
    "\n",
    "print(f'Test Accuracy (Overall): {acc_test_score}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1927f99b",
   "metadata": {},
   "source": [
    "##  Visualizing the attentions\n",
    "Defining helper functions\n",
    "<li>Given the image generate captions and attention scores</li>\n",
    "<li>Plot the attention scores in the image</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "064b8fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate caption\n",
    "def get_caps_from(model, features_tensors):\n",
    "    #generate the caption\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        features = model.encoder(features_tensors.to(device))\n",
    "        caps,alphas = model.decoder.generate_caption(features,vocab=test_dataset.vocab)\n",
    "        caption = ' '.join(caps)\n",
    "        show_image(features_tensors[0],title=caption)\n",
    "    \n",
    "    return caps,alphas\n",
    "#Show attention\n",
    "def plot_attention(img, result, attention_plot):\n",
    "    #untransform\n",
    "    img[0] = img[0] * 0.229\n",
    "    img[1] = img[1] * 0.224 \n",
    "    img[2] = img[2] * 0.225 \n",
    "    img[0] += 0.485 \n",
    "    img[1] += 0.456 \n",
    "    img[2] += 0.406\n",
    "    \n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "    temp_image = img\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "    len_result = len(result)\n",
    "    for l in range(len_result):\n",
    "        temp_att = attention_plot[l].reshape(7,7)\n",
    "        \n",
    "        ax = fig.add_subplot(len_result//2,len_result//2, l+1)\n",
    "        ax.set_title(result[l])\n",
    "        img = ax.imshow(temp_image)\n",
    "        ax.imshow(temp_att, cmap='gray', alpha=0.7, extent=img.get_extent())\n",
    "        \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def test_rand_image(model, test_loader):\n",
    "    dataiter = iter(test_loader)\n",
    "    images,_,_ = next(dataiter)\n",
    "\n",
    "    img = images[0].detach().clone()\n",
    "    img1 = images[0].detach().clone()\n",
    "    caps,alphas = get_caps_from(model, img.unsqueeze(0))\n",
    "\n",
    "    plot_attention(img1, caps, alphas)\n",
    "\n",
    "    #show the tensor image\n",
    "def show_image(img, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    \n",
    "    #unnormalize \n",
    "    img[0] = img[0] * 0.229\n",
    "    img[1] = img[1] * 0.224 \n",
    "    img[2] = img[2] * 0.225 \n",
    "    img[0] += 0.485 \n",
    "    img[1] += 0.456 \n",
    "    img[2] += 0.406\n",
    "    \n",
    "    img = img.numpy().transpose((1, 2, 0))\n",
    "      \n",
    "    plt.imshow(img)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ebe98616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAEICAYAAABf40E1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASQklEQVR4nO3de7BdZX3G8e8jl9BAKgQCxBBMoNEKViOmtBXxUqpcpjVgCw3Twaip6BRambHVIDM12In1Bs50HLFBGKNSIBaROMUKpgyMLXI1BEKIJBAgJCZyUVCsNuHpH+s94+ZwTnKyL9n7+D6fmT177XetdfZvzZrznLXXXmf9ZJuIqNdL+l1ARPRXQiCicgmBiMolBCIqlxCIqFxCIKJyCYHfAJIWSfpamT5c0s8k7dHvumJ8SAj8hrH9qO39bG/vVw2SLOnnJYyGHh9umX+UpOWSfirpWUk3SXrDsJ+xQNIDZf4WSf8hadLu35rffAmB6ApJhwwbem0Jo6HHp8tyRwL/DdwLzAReBlwL3CDpj8oybwY+AZxpexLwKmBZy3tNkaSeb1QlEgIDStJCSevLX8L7JZ02xvVmlL/Ee5bXLyt/dZ+StE7S+1qWXSRpmaSvlPdZLWnOLtR4qKR/kHQ/sGiMqy0CbrV9ge2nbD9r+1+ArwKfKsv8flnmBwBluaW2ny3z3ws8LOlCSTPHWm+MLCEwuNYDxwMvBS4EviZpahs/50pgI81f3L8APiHphJb57wCuAvYHlgOf39EPk7SXpHdK+hawFngN8HfAOWOs523A10cYXwYcJ2kicBtwYvklP07ShNYFbX8KmAccDNxZPk68q6wbu8p2HuPgAawE5o4ybxHwtTI9AzCwJzAd2A5Maln2n4Evt6z33ZZ5RwG/2EEN/wRsBW6h+Ws8aZTlDDwD/KTlcWKZtw04aYR1fresN628Phn4Vln3Z8DFwB4jrDcBOAO4HngK+FK/99V4e+RIYECVv2wrJf1E0k+AVwMH7eKPeRnwlH99GA3wCDCt5fWPWqafA/YZ+igxglcCe9EE0qphP3e4Y2zv3/L4Thl/AhjpiGYq8DzwNIDtb9v+M2AyMBd4N/DXw1ey/UtgVanpV8Dv7aCmGEFCYABJejlwKXAucKDt/YH7gF09GbYJmDzsrPrhwOPt1GX7DGA2zS/y1eUcwkJJh+3Cj/kucPoI42fQnAd4bth7Pm97BfBfNEEIgKQDJZ0r6fYyb0/grbb/YJc2KhICA2pfmkPjHwNIeg8tvwBjZfsx4H+Af5a0j6TXAAuAK9otzPYjtj8O/A7wNzRHB6slLRrjj7gQeIOkxZImS5ok6W+BdwEfAZA0V9I8SQeocSzwZuD7Zf4CYEMZuxCYbvvDtte0u101G+2wL/rI9v2SLgJupTlE/grN12rtOBP4Is1RwdPAx2zf2IUaDdwM3CzpXGDWsEXukdR6s4ov2T7P9oOS3gh8kuYX+SXAnTTnDIa28Wmak42fp/nMvxn4jO2h8LoVeLntpzrdjgCVkysRUal8HIioXEIgonI9CwFJJ0laW65SW9ir94mIzvTknED5D7Yf0lwdthG4g+Y68Pu7/mYR0ZFefTtwLLDO9kMAkq6iueBjxBCY+Fv7+KUvzT+IRfTSj7Y88YTtKcPHexUC04DHWl5vBF5wEYeks4GzAX570n4sOOvPe1RKRAAs/uy/PjLSeK/OCYx0ZdsLPnfYXmJ7ju05Eyfu06MyImJnehUCG2n+eWXIYTQXq0TEgOlVCNwBzJI0U9LeNP/2ubxH7xURHejJOQHb28qlpN8B9gAut726F+8VEZ3p2f8O2L6e5n+8I2KA5YrBiMolBCIqlxCIqFxCIKJyCYGIyiUEIiqXEIioXEIgonIJgYjKJQQiKpcQiKhcQiCicgmBiMolBCIqlxCIqFzbISBpuqSbJK0p3Wk/WMYXSXq8tNVeKemU7pUbEd3WyU1FtgEfsn13aX19l6ShRpefs/3ZzsuLiF5rOwRsb6bpFovtZyWtobnVeESMI105JyBpBvA64LYydK6kVZIul3TAKOucLelOSXc+99z/dqOMiGhDxyEgaT/gGuA8288AlwBHArNpjhQuGmm99B2IGAwdhYCkvWgC4Arb3wCwvcX2dtvPA5fStCSLiAHVybcDAi4D1ti+uGV8astipwH3tV9eRPRaJ98OHAecBdwraWUZ+yhwpqTZNG3HNgDv7+A9IqLHOvl24HuM3HMwvQYixpFcMRhRuYRAROUSAhGVSwhEVC4hEFG5hEBE5RICEZVLCERULiEQUbmEQETlEgIRlUsIRFQuIRBRuYRAROUSAhGV6+SmIkjaADwLbAe22Z4jaTJwNTCD5qYiZ9h+urMyI6JXunEk8Fbbs23PKa8XAitszwJWlNcRMaB68XFgLrC0TC8FTu3Be0REl3QaAgZukHSXpLPL2CGlMclQg5KDR1oxfQciBkNH5wSA42xvknQwcKOkB8a6ou0lwBKAqYdOcYd1RESbOjoSsL2pPG8FrqXpMbBl6Lbj5Xlrp0VGRO900ndg39KIFEn7Am+n6TGwHJhfFpsPXNdpkRHRO518HDgEuLbpQcKewL/Z/k9JdwDLJC0AHgVO77zMiOiVTvoOPAS8doTxJ4ETOikqInafXDEYUbmEQETlEgIRlUsIRFQuIRBRuYRAROUSAhGVSwhEVC4hEFG5hEBE5RICEZVLCERULiEQUbmEQETlEgIRlWv7fgKSXknTX2DIEcA/AvsD7wN+XMY/avv6dt8nInqrk5uKrAVmA0jaA3ic5j6D7wE+Z/uz3SgwInqrWx8HTgDW236kSz8vInaTboXAPODKltfnSlol6XJJB3TpPSKiBzoOAUl7A+8Avl6GLgGOpPmosBm4aJT10nwkYgB040jgZOBu21sAbG+xvd3288ClNL0IXsT2EttzbM+ZOHGfLpQREe3oRgicSctHgaHGI8VpNL0IImJAddqafCLwNuD9LcOfljSbpk/hhmHzImLAdBQCtp8DDhw2dlZHFUXEbpUrBiMqlxCIqFxCIKJyCYGIyiUEIiqXEIioXEIgonIJgYjKJQQiKpcQiKhcQiCicgmBiMolBCIqlxCIqFxCIKJyCYGIyu00BModg7dKuq9lbLKkGyU9WJ4PaJl3vqR1ktZKOrFXhUdEd4zlSODLwEnDxhYCK2zPAlaU10g6iub240eXdb5QGpNExIDaaQjYvgV4atjwXGBpmV4KnNoyfpXtX9p+GFjHKHcbjojB0O45gUNsbwYozweX8WnAYy3LbSxjL5K+AxGDodsnBjXCmEdaMH0HIgZDuyGwZai/QHneWsY3AtNbljsM2NR+eRHRa+2GwHJgfpmeD1zXMj5P0gRJM4FZwO2dlRgRvbTTvgOSrgTeAhwkaSPwMeCTwDJJC4BHgdMBbK+WtAy4H9gGnGN7e49qj4gu2GkI2D5zlFknjLL8YmBxJ0VFxO6TKwYjKpcQiKhcQiCicgmBiMolBCIqlxCIqFxCIKJyCYGIyiUEIiqXEIioXEIgonIJgYjKJQQiKpcQiKhcQiCicu32HfiMpAckrZJ0raT9y/gMSb+QtLI8vtjD2iOiC9rtO3Aj8GrbrwF+CJzfMm+97dnl8YHulBkRvdJW3wHbN9jeVl5+n+aGohExDnXjnMB7gW+3vJ4p6QeSbpZ0/Ggrpe9AxGDY6T0Gd0TSBTQ3FL2iDG0GDrf9pKTXA9+UdLTtZ4ava3sJsARg6qFTRuxNEBG91/aRgKT5wJ8Cf2XbAKX92JNl+i5gPfCKbhQaEb3RVghIOgn4CPAO28+1jE8ZakAq6QiavgMPdaPQiOiNdvsOnA9MAG6UBPD98k3Am4CPS9oGbAc+YHt4M9OIGCDt9h24bJRlrwGu6bSoiNh9csVgROUSAhGVSwhEVC4hEFG5hEBE5RICEZVLCERULiEQUbmEQETlEgIRlUsIRFQuIRBRuYRAROUSAhGVSwhEVK7dvgOLJD3e0l/glJZ550taJ2mtpBN7VXhEdEe7fQcAPtfSX+B6AElHAfOAo8s6Xxi63VhEDKa2+g7swFzgqnLD0YeBdcCxHdQXET3WyTmBc0sbssslHVDGpgGPtSyzsYy9SPoORAyGdkPgEuBIYDZNr4GLyrhGWHbEngK2l9ieY3vOxIn7tFlGRHSqrRCwvcX2dtvPA5fy60P+jcD0lkUPAzZ1VmJE9FK7fQemtrw8DRj65mA5ME/SBEkzafoO3N5ZiRHRS+32HXiLpNk0h/obgPcD2F4taRlwP017snNsb+9J5RHRFV3tO1CWXwws7qSoiNh9csVgROUSAhGVSwhEVC4hEFG5hEBE5RICEZVLCERULiEQUbmEQETlEgIRlUsIRFQuIRBRuYRAROUSAhGVSwhEVC4hEFG5dpuPXN3SeGSDpJVlfIakX7TM+2IPa4+ILtjpnYVomo98HvjK0IDtvxyalnQR8NOW5dfbnt2l+iKix8Zye7FbJM0YaZ4kAWcAf9zluiJiN+n0nMDxwBbbD7aMzZT0A0k3Szp+tBXTfCRiMIzl48COnAlc2fJ6M3C47SclvR74pqSjbT8zfEXbS4AlAFMPnTJig5KI6L22jwQk7Qm8E7h6aKz0IHyyTN8FrAde0WmREdE7nXwc+BPgAdsbhwYkTRnqQizpCJrmIw91VmJE9NJYviK8ErgVeKWkjZIWlFnzeOFHAYA3Aask3QP8O/AB22PtaBwRfdBu8xFsv3uEsWuAazovKyJ2l1wxGFG5hEBE5RICEZVLCERULiEQUbmEQETlEgIRlUsIRFQuIRBRuYRAROUSAhGVSwhEVC4hEFG5hEBE5RICEZUby01Fpku6SdIaSaslfbCMT5Z0o6QHy/MBLeucL2mdpLWSTuzlBkREZ8ZyJLAN+JDtVwF/CJwj6ShgIbDC9ixgRXlNmTcPOBo4CfjC0C3HImLw7DQEbG+2fXeZfhZYA0wD5gJLy2JLgVPL9FzgqnLT0YeBdcCxXa47Irpkl84JlCYkrwNuAw6xvRmaoAAOLotNAx5rWW1jGRv+s9J3IGIAjDkEJO1Hc//A80bqI9C66AhjL+orYHuJ7Tm250ycuM9Yy4iILhtTCEjaiyYArrD9jTK8RdLUMn8qsLWMbwSmt6x+GLCpO+VGRLeN5dsBAZcBa2xf3DJrOTC/TM8HrmsZnydpgqSZNL0Hbu9eyRHRTWNpQ3YccBZw71ALcuCjwCeBZaUPwaPA6QC2V0taBtxP883COba3d7vwiOiOsfQd+B4jf84HOGGUdRYDizuoKyJ2k1wxGFG5hEBE5RICEZVLCERULiEQUbmEQETlEgIRlUsIRFQuIRBRuYRAROUSAhGVSwhEVC4hEFG5hEBE5RICEZVLCERULiEQUTnZL7oR8O4vQvox8HPgiX7X0oGDGN/1w/jfhvFeP/R2G15ue8rwwYEIAQBJd9qe0+862jXe64fxvw3jvX7ozzbk40BE5RICEZUbpBBY0u8COjTe64fxvw3jvX7owzYMzDmBiOiPQToSiIg+SAhEVK7vISDpJElrJa2TtLDf9YyVpA2S7pW0UtKdZWyypBslPVieD+h3nUMkXS5pq6T7WsZGrVfS+WWfrJV0Yn+qfqFRtmGRpMfLflgp6ZSWeQO1DZKmS7pJ0hpJqyV9sIz3dz/Y7tsD2ANYDxwB7A3cAxzVz5p2ofYNwEHDxj4NLCzTC4FP9bvOltreBBwD3LezeoGjyr6YAMws+2iPAd2GRcDfj7DswG0DMBU4pkxPAn5Y6uzrfuj3kcCxwDrbD9n+FXAVMLfPNXViLrC0TC8FTu1fKS9k+xbgqWHDo9U7F7jK9i9tPwyso9lXfTXKNoxm4LbB9mbbd5fpZ4E1wDT6vB/6HQLTgMdaXm8sY+OBgRsk3SXp7DJ2iO3N0Oxw4OC+VTc2o9U73vbLuZJWlY8LQ4fSA70NkmYArwNuo8/7od8hMFK34/HyneVxto8BTgbOkfSmfhfUReNpv1wCHAnMBjYDF5Xxgd0GSfsB1wDn2X5mR4uOMNb1beh3CGwEpre8PgzY1KdadontTeV5K3AtzWHaFklTAcrz1v5VOCaj1Ttu9ovtLba3234euJRfHy4P5DZI2osmAK6w/Y0y3Nf90O8QuAOYJWmmpL2BecDyPte0U5L2lTRpaBp4O3AfTe3zy2Lzgev6U+GYjVbvcmCepAmSZgKzgNv7UN9ODf3yFKfR7AcYwG2QJOAyYI3ti1tm9Xc/DMAZ31NozpKuBy7odz1jrPkImrO29wCrh+oGDgRWAA+W58n9rrWl5itpDpf/j+YvzIId1QtcUPbJWuDkfte/g234KnAvsKr80kwd1G0A3khzOL8KWFkep/R7P+Sy4YjK9fvjQET0WUIgonIJgYjKJQQiKpcQiKhcQiCicgmBiMr9P5BM6qEiK3wPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "num must be 1 <= num <= 1, not 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0d/kx07xpsn40v0mbjthb6sbc5h0000gq/T/ipykernel_24518/3972265883.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# local_model_path = 'simple-model.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model = load_model(local_model_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest_rand_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/0d/kx07xpsn40v0mbjthb6sbc5h0000gq/T/ipykernel_24518/4263616265.py\u001b[0m in \u001b[0;36mtest_rand_image\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mcaps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_caps_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mplot_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m#show the tensor image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/0d/kx07xpsn40v0mbjthb6sbc5h0000gq/T/ipykernel_24518/4263616265.py\u001b[0m in \u001b[0;36mplot_attention\u001b[0;34m(img, result, attention_plot)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mtemp_att\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_plot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen_result\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_result\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36madd_subplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    770\u001b[0m             projection_class, pkw = self._process_projection_requirements(\n\u001b[1;32m    771\u001b[0m                 *args, **kwargs)\n\u001b[0;32m--> 772\u001b[0;31m             \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubplot_class_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprojection_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_axes_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/matplotlib/axes/_subplots.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fig, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_axes_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# This will also update the axes position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_subplotspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSubplotSpec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_subplot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     @_api.deprecated(\n",
      "\u001b[0;32m~/miniconda/envs/thesis-py38/lib/python3.8/site-packages/matplotlib/gridspec.py\u001b[0m in \u001b[0;36m_from_subplot_args\u001b[0;34m(figure, args)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    609\u001b[0m                     f\"num must be 1 <= num <= {rows*cols}, not {num!r}\")\n\u001b[1;32m    610\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: num must be 1 <= num <= 1, not 2"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# model_path = '/home/space/datasets/COA/models/baseline/attention_model_state.pth'\n",
    "# local_model_path = 'simple-model.pth'\n",
    "# model = load_model(local_model_path)\n",
    "test_rand_image(model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bdb42f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
